{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Multi-Class Image Classification using PyTorch for Beginners\n","\n","I have fine tuned pre-trained VGG16 model, you can create your own model or use any pre-built pytorch model. More details [here](https://pytorch.org/docs/stable/torchvision/models.html)."]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import time\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data import RandomSampler\n","\n","import torchvision.transforms as T\n","import torchvision.models as models\n","from torchvision.utils import make_grid\n","from torchvision.datasets import ImageFolder\n","\n","from matplotlib import pyplot as plt\n","\n","DIR_TRAIN = \"./data/train/\"\n","DIR_VALID = \"./data/valid/\"\n","DIR_TEST = \"./data/test/\""]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Classes:  525\n","Total train images:  84434\n","Total valid images:  2620\n","Total test images:  2620\n"]}],"source":["### Exploring Dataset\n","\n","classes = os.listdir(DIR_TRAIN)\n","print(\"Total Classes: \",len(classes))\n","\n","#Counting total train, valid & test images\n","\n","train_count = 0\n","valid_count = 0\n","test_count = 0\n","for _class in classes:\n","    train_count += len(os.listdir(DIR_TRAIN + _class))\n","    valid_count += len(os.listdir(DIR_VALID + _class))\n","    test_count += len(os.listdir(DIR_TEST + _class))\n","\n","print(\"Total train images: \",train_count)\n","print(\"Total valid images: \",valid_count)\n","print(\"Total test images: \",test_count)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### Creating a list of all images : DIR_TRAIN/class_folder/img.jpg - FOR METHOD 2 of data loading\n","#   A dict for mapping class labels to index\n","\n","train_imgs = []\n","valid_imgs = []\n","test_imgs = []\n","\n","for _class in classes:\n","    \n","    for img in os.listdir(DIR_TRAIN + _class):\n","        train_imgs.append(DIR_TRAIN + _class + \"/\" + img)\n","    \n","    for img in os.listdir(DIR_VALID + _class):\n","        valid_imgs.append(DIR_VALID + _class + \"/\" + img)\n","        \n","    for img in os.listdir(DIR_TEST + _class):\n","        test_imgs.append(DIR_TEST + _class + \"/\" + img)\n","\n","class_to_int = {classes[i] : i for i in range(len(classes))}\n","    "]},{"cell_type":"markdown","metadata":{},"source":["There are multiple ways to load images from the dataset, I have used 2 such methods:\n","1. Using ImageFolder Class\n","2. Using Dataset Class"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### Loading Classification Dataset - FOR METHOD 2: For multi-class data, by inheriting Dataset class\n","\n","def get_transform():\n","    return T.Compose([T.ToTensor()])\n","\n","class BirdDataset(Dataset):\n","    \n","    def __init__(self, imgs_list, class_to_int, transforms = None):\n","        \n","        super().__init__()\n","        self.imgs_list = imgs_list\n","        self.class_to_int = class_to_int\n","        self.transforms = transforms\n","        \n","        \n","    def __getitem__(self, index):\n","    \n","        image_path = self.imgs_list[index]\n","        \n","        #Reading image\n","        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n","        image /= 255.0\n","        \n","        #Retriving class label\n","        label = image_path.split(\"/\")[-2]\n","        label = self.class_to_int[label]\n","        \n","        #Applying transforms on image\n","        if self.transforms:\n","            image = self.transforms(image)\n","        \n","        return image, label\n","        \n","        \n","        \n","    def __len__(self):\n","        return len(self.imgs_list)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### Loading Classification Dataset\n","\n","\"\"\"\n","# Method 1: For multi-class data directly from folders using ImageFolder\n","train_dataset = ImageFolder(root = DIR_TRAIN, transform = T.ToTensor())\n","valid_dataset = ImageFolder(root = DIR_VALID, transform = T.ToTensor())\n","test_dataset = ImageFolder(root = DIR_TEST, transform = T.ToTensor())\n","\"\"\"\n","\n","# Method 2: Using Dataset Class\n","train_dataset = BirdDataset(train_imgs, class_to_int, get_transform())\n","valid_dataset = BirdDataset(valid_imgs, class_to_int, get_transform())\n","test_dataset = BirdDataset(test_imgs, class_to_int, get_transform())\n","\n","#Data Loader  -  using Sampler (YT Video)\n","train_random_sampler = RandomSampler(train_dataset)\n","valid_random_sampler = RandomSampler(valid_dataset)\n","test_random_sampler = RandomSampler(test_dataset)\n","\n","#Shuffle Argument is mutually exclusive with Sampler!\n","train_data_loader = DataLoader(\n","    dataset = train_dataset,\n","    batch_size = 16,\n","    sampler = train_random_sampler,\n","    num_workers = 4,\n",")\n","\n","valid_data_loader = DataLoader(\n","    dataset = valid_dataset,\n","    batch_size = 16,\n","    sampler = valid_random_sampler,\n","    num_workers = 4,\n",")\n","\n","test_data_loader = DataLoader(\n","    dataset = test_dataset,\n","    batch_size = 16,\n","    sampler = test_random_sampler,\n","    num_workers = 4,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Visualize one training batch\n","for images, labels in train_data_loader:\n","    fig, ax = plt.subplots(figsize = (10, 10))\n","    ax.set_xticks([])\n","    ax.set_yticks([])\n","    ax.imshow(make_grid(images, 4).permute(1,2,0))\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### Define model\n","model = models.vgg16(pretrained = True)\n","\n","### Modifying last few layers and no of classes\n","# NOTE: cross_entropy loss takes unnormalized op (logits), then function itself applies softmax and calculates loss, so no need to include softmax here\n","model.classifier = nn.Sequential(\n","    nn.Linear(25088, 4096, bias = True),\n","    nn.ReLU(inplace = True),\n","    nn.Dropout(0.4),\n","    nn.Linear(4096, 2048, bias = True),\n","    nn.ReLU(inplace = True),\n","    nn.Dropout(0.4),\n","    nn.Linear(2048, 200)\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### Get device\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","torch.cuda.empty_cache()\n","\n","model.to(device)\n","\n","### Training Details\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.75)\n","criterion = nn.CrossEntropyLoss()\n","\n","train_loss = []\n","train_accuracy = []\n","\n","val_loss = []\n","val_accuracy = []\n","\n","epochs = 20\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def calc_accuracy(true,pred):\n","    pred = F.softmax(pred, dim = 1)\n","    true = torch.zeros(pred.shape[0], pred.shape[1]).scatter_(1, true.unsqueeze(1), 1.)\n","    acc = (true.argmax(-1) == pred.argmax(-1)).float().detach().numpy()\n","    acc = float((100 * acc.sum()) / len(acc))\n","    return round(acc, 4)"]},{"cell_type":"markdown","metadata":{},"source":["I did not execute training code given below as it takes time, you can fork this notebook and try yourself."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["### Training Code\n","\n","for epoch in range(epochs):\n","    \n","    start = time.time()\n","    \n","    #Epoch Loss & Accuracy\n","    train_epoch_loss = []\n","    train_epoch_accuracy = []\n","    _iter = 1\n","    \n","    #Val Loss & Accuracy\n","    val_epoch_loss = []\n","    val_epoch_accuracy = []\n","    \n","    # Training\n","    for images, labels in train_data_loader:\n","        \n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        #Reset Grads\n","        optimizer.zero_grad()\n","        \n","        #Forward ->\n","        preds = model(images)\n","        \n","        #Calculate Accuracy\n","        acc = calc_accuracy(labels.cpu(), preds.cpu())\n","        \n","        #Calculate Loss & Backward, Update Weights (Step)\n","        loss = criterion(preds, labels)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        #Append loss & acc\n","        loss_value = loss.item()\n","        train_epoch_loss.append(loss_value)\n","        train_epoch_accuracy.append(acc)\n","        \n","        if _iter % 500 == 0:\n","            print(\"> Iteration {} < \".format(_iter))\n","            print(\"Iter Loss = {}\".format(round(loss_value, 4)))\n","            print(\"Iter Accuracy = {} % \\n\".format(acc))\n","        \n","        _iter += 1\n","    \n","    #Validation\n","    for images, labels in valid_data_loader:\n","        \n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        #Forward ->\n","        preds = model(images)\n","        \n","        #Calculate Accuracy\n","        acc = calc_accuracy(labels.cpu(), preds.cpu())\n","        \n","        #Calculate Loss\n","        loss = criterion(preds, labels)\n","        \n","        #Append loss & acc\n","        loss_value = loss.item()\n","        val_epoch_loss.append(loss_value)\n","        val_epoch_accuracy.append(acc)\n","    \n","    \n","    train_epoch_loss = np.mean(train_epoch_loss)\n","    train_epoch_accuracy = np.mean(train_epoch_accuracy)\n","    \n","    val_epoch_loss = np.mean(val_epoch_loss)\n","    val_epoch_accuracy = np.mean(val_epoch_accuracy)\n","    \n","    end = time.time()\n","    \n","    train_loss.append(train_epoch_loss)\n","    train_accuracy.append(train_epoch_accuracy)\n","    \n","    val_loss.append(val_epoch_loss)\n","    val_accuracy.append(val_epoch_accuracy)\n","    \n","    #Print Epoch Statistics\n","    print(\"** Epoch {} ** - Epoch Time {}\".format(epoch, int(end-start)))\n","    print(\"Train Loss = {}\".format(round(train_epoch_loss, 4)))\n","    print(\"Train Accuracy = {} % \\n\".format(train_epoch_accuracy))\n","    print(\"Val Loss = {}\".format(round(val_epoch_loss, 4)))\n","    print(\"Val Accuracy = {} % \\n\".format(val_epoch_accuracy))\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":534640,"sourceId":5468571,"sourceType":"datasetVersion"}],"dockerImageVersionId":29955,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
